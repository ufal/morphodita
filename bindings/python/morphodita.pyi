import typing as t

_T = t.TypeVar('_T')

class SwigIterator(t.Protocol, t.Generic[_T]):
    def __next__(self) -> _T: ...
    def __iter__(self) -> "SwigIterator[_T]": ...

class SwigVector(t.Protocol, t.Generic[_T]):
    def __len__(self) -> int: ...
    def __getitem__(self, key: int) -> _T: ...
    def __setitem__(self, key: int, value: _T) -> None: ...
    def __delitem__(self, key: int) -> None: ...
    def __iter__(self) -> SwigIterator[_T]: ...
    def append(self, value: _T) -> None: ...
    def pop(self) -> _T: ...
    def size(self) -> int: ...
    def resize(self, new_size: int) -> None: ...
    def clear(self) -> None: ...

class Indices(SwigVector[int]):
    ...

class Forms(SwigVector[str]):
    ...

class TaggedForm:
  form: str
  tag: str
class TaggedForms(SwigVector[TaggedForm]):
    ...

class TaggedLemma:
  lemma: str
  tag: str
class TaggedLemmas(SwigVector[TaggedLemma]):
    ...
class Analyses(SwigVector[TaggedLemmas]):
    ...

class TaggedLemmaForms:
  lemma: str
  forms: TaggedForms
class TaggedLemmasForms(SwigVector[TaggedLemmaForms]):
    ...

class TokenRange:
  start: int
  length: int
class TokenRanges(SwigVector[TokenRange]):
    ...

class DerivatedLemma:
  lemma: str
class DerivatedLemmas(SwigVector[DerivatedLemma]):
    ...

class Version:
  major: int
  minor: int
  patch: int
  prerelease: str
  @staticmethod
  def current() -> Version: ...

class Tokenizer:
  @staticmethod
  def newVerticalTokenizer() -> Tokenizer: ...
  @staticmethod
  def newCzechTokenizer() -> Tokenizer: ...
  @staticmethod
  def newEnglishTokenizer() -> Tokenizer: ...
  @staticmethod
  def newGenericTokenizer() -> Tokenizer: ...
  def setText(self, text: str): ...
  def nextSentence(self, forms: t.Optional[Forms], tokens: t.Optional[TokenRanges]) -> bool: ...

class TagsetConverter:
  @staticmethod
  def newIdentityConverter() -> TagsetConverter: ...
  @staticmethod
  def newPdtToConll2009Converter() -> TagsetConverter: ...
  @staticmethod
  def newStripLemmaCommentConverter(morpho: Morpho) -> TagsetConverter: ...
  @staticmethod
  def newStripLemmaIdConverter(morpho: Morpho) -> TagsetConverter: ...
  def convert(self, lemma: TaggedLemma): ...
  def convertAnalyzed(self, lemmas: TaggedLemmas): ...
  def convertGenerated(self, forms: TaggedLemmasForms): ...

class Derivator:
  def parent(self, lemma: str, parent: DerivatedLemma) -> bool: ...
  def children(self, lemma: str, children: DerivatedLemmas) -> bool: ...

class DerivationFormatter:
  @staticmethod
  def newNoneDerivationFormatter() -> DerivationFormatter: ...
  @staticmethod
  def newRootDerivationFormatter(derivator: Derivator) -> DerivationFormatter: ...
  @staticmethod
  def newPathDerivationFormatter(derivator: Derivator) -> DerivationFormatter: ...
  @staticmethod
  def newTreeDerivationFormatter(derivator: Derivator) -> DerivationFormatter: ...
  @staticmethod
  def newDerivationFormatter(name: str, derivator: Derivator) -> DerivationFormatter: ...
  def formatDerivation(self, lemma: str) -> str: ...
  def formatTaggedLemma(self, tagged_lemma: TaggedLemma, converter: t.Optional[TagsetConverter] = None): ...
  def formatTaggedLemmas(self, tagged_lemmas: TaggedLemmas, converter: t.Optional[TagsetConverter] = None): ...

class Morpho:
  NO_GUESSER = 0
  GUESSER = 1
  GUESSER_UNSPECIFIED = -1
  @staticmethod
  def load(fname: str) -> Morpho: ...
  def analyze(self, form: str, guesser: int, lemmas: TaggedLemmas) -> int: ...
  def generate(self, lemma: str, tag_wildcard: str, guesser: int, forms: TaggedLemmasForms) -> int: ...
  def rawLemma(self, lemma: str) -> str: ...
  def lemmaId(self, lemma: str) -> str: ...
  def rawForm(self, form: str) -> str: ...
  def newTokenizer(self) -> Tokenizer: ...
  def getDerivator(self) -> Derivator: ...

class Tagger:
  @staticmethod
  def load(fname: str) -> Tagger: ...
  def getMorpho(self) -> Morpho: ...
  def tag(self, forms: Forms, tags: TaggedLemmas, guesser: int = Morpho.GUESSER_UNSPECIFIED): ...
  def tagAnalyzed(self, forms: Forms, analyses: Analyses, tags: Indices): ...
  def newTokenizer(self) -> Tokenizer: ...
